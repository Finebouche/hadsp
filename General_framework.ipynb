{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754c1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "path_root = Path( '/project_ghent/HADSP/reservoirpy/')\n",
    "sys.path.append(str(path_root))\n",
    "path_root = Path( '/project_ghent/HADSP/hadsp/')\n",
    "sys.path.append(str(path_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f790cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from seaborn import heatmap, color_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67127097-7065-4551-9b82-3d12c176a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "# Utility functions\n",
    "from reservoir.utility import show_matrice\n",
    "\n",
    "# SEED\n",
    "SEED = 49387"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7bc227",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reservoir functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f980d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T09:31:36.544255Z",
     "start_time": "2022-06-10T09:31:36.544249Z"
    },
    "init_cell": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from reservoir.reservoir import update_reservoir, ridge_regression, train, run\n",
    "from reservoir.activation_functions import tanh, heaviside, sigmoid\n",
    "\n",
    "# the activation function choosen for the rest of the experiment\n",
    "# activation_function = lambda x : sigmoid(2*(x-0.5))\n",
    "activation_function = lambda x : tanh(x)\n",
    "\n",
    "plt.plot(np.linspace(0, 2, 100), activation_function(np.linspace(0, 2, 100)))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb44384e-7cbc-4611-a015-e1c073f61aa9",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "Lots of different on availabale : https://towardsdatascience.com/a-data-lakes-worth-of-audio-datasets-b45b88cd4ad\n",
    "\n",
    "Classification: \n",
    "https://arxiv.org/abs/1803.07870\n",
    "\n",
    "https://github.com/FilippoMB/Time-series-classification-and-clustering-with-Reservoir-Computing\n",
    "\n",
    "Multivariate:\n",
    "https://www.timeseriesclassification.com/dataset.php"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bc3d35-72f1-4fc8-a452-e0699b4d507d",
   "metadata": {},
   "source": [
    "## Mackey-Glass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb2dcf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from reservoirpy.datasets import mackey_glass\n",
    "\n",
    "timesteps = 10000\n",
    "mg_inputs = mackey_glass(timesteps, tau=17, a=0.2, b=0.1, n=10, x0=1.2, h=1, seed=None)\n",
    "\n",
    "# Define the time step of your Mackey-Glass system\n",
    "dt = 0.00001\n",
    "\n",
    "# Compute the equivalent sampling rate\n",
    "sampling_rate = 1 / dt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(range(1000), mg_inputs[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533985e3-1953-4347-bd40-b88c367cbc1e",
   "metadata": {},
   "source": [
    "## Japanese voyels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e868f68b-4405-48db-9bbc-34084d6fb282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.datasets import japanese_vowels\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = japanese_vowels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbc8ae9-7bca-45bc-8aab-23be0c750942",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pretrain = np.concatenate(X_train, axis=0)\n",
    "X_pretrain.shape\n",
    "filtered_data = X_pretrain.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb570d-fe73-4a2a-99bc-a9d732b0aeae",
   "metadata": {},
   "source": [
    "## InsectWingbeat"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2a91019-8d72-486a-be3e-6e8c860580a6",
   "metadata": {},
   "source": [
    "from scipy.io import arff\n",
    "from io import StringIO\n",
    "\n",
    "with open('datasets/InsectWingbeat/InsectWingbeat_TRAIN.arff', 'r') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370aa8a6-4c5d-4c29-9bfe-a36dcd37d1d8",
   "metadata": {},
   "source": [
    "## MELD\n",
    "\n",
    "https://github.com/declare-lab/MELD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4016e3f6-92e5-4403-a145-9eaf9af0cdac",
   "metadata": {},
   "source": [
    "## Free Spoken Digits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0675739-5d2e-497f-b990-008b7d0e5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.load_datasets import load_FSDD_dataset\n",
    "\n",
    "data_dir = 'datasets/fsdd/free-spoken-digit-dataset-master/recordings'  # Path to the extracted dataset\n",
    "sampling_rate, X_train, X_test, Y_train, Y_test = load_FSDD_dataset(data_dir, seed=SEED)\n",
    "# Check the shapes of the datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Y_test shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a468ca5c",
   "metadata": {},
   "source": [
    "# New inputs creation with band filters\n",
    "\n",
    "Spectrograms_vs_Cochleagrams : \n",
    "* https://www.researchgate.net/publication/340510607_Speech_recognition_using_very_deep_neural_networks_Spectrograms_vs_Cochleagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008da94-d239-4c67-b563-db3cbdfa7895",
   "metadata": {},
   "source": [
    "## Pretrain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3ba2b7-c2d0-4659-8106-296607b228b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a long time (15min with half the samples, instant with 20 which is enought for pretraining)\n",
    "X_pretrain = np.concatenate(X_train[:20], axis=0)\n",
    "print(X_pretrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e57e07-e48c-4e28-80e9-ad95894d0a2e",
   "metadata": {},
   "source": [
    "## Spectral density and peak selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ad0f4-4dbc-4b97-8d28-8ffb357715d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.multivariate_generation import generate_multivariate_dataset, extract_peak_frequencies\n",
    "\n",
    "filtered_peak_freqs = extract_peak_frequencies(X_pretrain.flatten(), sampling_rate, nperseg=1024, visualize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766304bc-3c47-4813-9828-91d8fed5845b",
   "metadata": {},
   "source": [
    "## Applying normal band pass filter on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690a984-394f-4be3-912c-ee2ca4cc1ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pretrain_band, X_train_band, X_test_band = generate_multivariate_dataset(filtered_peak_freqs, X_pretrain, X_train, X_test, sampling_rate, nb_jobs=-1, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b859e5-c6dd-4086-ac56-42a7de3ed25e",
   "metadata": {},
   "source": [
    "## Standardizing the amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb45e001-4920-47e1-8dbb-6681cf9b32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# pretrain\n",
    "filtered_data = scaler.fit_transform(X_pretrain_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f35f5-0636-4732-86f4-5c60e9cd5e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "X_train_band = [np.array([scaler.fit_transform(time_serie.reshape(-1, 1)).flatten() for time_serie in x]) for x in X_train_band]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ff37f7-38d5-4fcf-a36e-7f9edb22d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "X_test_band = [np.array([scaler.fit_transform(time_serie.reshape(-1, 1)).flatten() for time_serie in x]) for x in X_test_band]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3946e-5918-489b-a18d-a92a8f751adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_band[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd93f662-f197-4b0a-a140-090f3c0909d2",
   "metadata": {},
   "source": [
    "# Generating reservoirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385de4f8",
   "metadata": {},
   "source": [
    "## Creating from HADSP + bandfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b39f1d-d8d6-451b-8d4d-b8f8f74a498d",
   "metadata": {},
   "source": [
    "### Plot  pretrain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab965ec2-e31c-475e-b452-05c9dbfde13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min window size to get all the dynamics ? \n",
    "min_window_size = sampling_rate/filtered_peak_freqs[-1]\n",
    "\n",
    "min_window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd00d3f-9b0c-475f-bac9-b46e5f92adfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Compute the moving average \n",
    "window_size = 5\n",
    "weights = np.repeat(1.0, window_size)/window_size\n",
    "ma = np.array([np.convolve(d, weights, 'valid') for d in (filtered_data)])\n",
    "\n",
    "#CPlot the two for different frequencies\n",
    "NB_1 = 3\n",
    "fig, ax = plt.subplots(2, 1, figsize=(24,12))\n",
    "ax[0].plot(range(500), filtered_data[NB_1, 1000:1500], label='Time serie')\n",
    "ax[0].plot(range(500), ma[NB_1, 1000:1500], label='Moving average')\n",
    "NB_2 = 10\n",
    "ax[0].legend(fontsize=26)\n",
    "ax[1].plot(range(500), filtered_data[NB_2, 1000:1500], label='Time serie')\n",
    "ax[1].plot(range(500), ma[NB_2, 1000:1500], label='Moving average')\n",
    "\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "ax[0].tick_params(axis='both', labelsize=26)\n",
    "ax[1].tick_params(axis='both', labelsize=26)\n",
    "\n",
    "\n",
    "# draw vertical lines to represent the window for some points\n",
    "for x in range(100, 500, 100):\n",
    "    ax[0].axvspan(x, x+window_size, color='g', alpha=0.2)\n",
    "for x in range(100, 500, 100):\n",
    "    ax[1].axvspan(x, x+window_size, color='g', alpha=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df206ba-36a2-4468-b719-7bc819114b1a",
   "metadata": {},
   "source": [
    "## Construct matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6435e2-6f19-4987-9309-ab74694678fd",
   "metadata": {},
   "source": [
    "### Shared parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f44547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "# We want the size of the reservoir to be at least 200\n",
    "K = math.ceil(200 / filtered_peak_freqs.shape[0])\n",
    "n = filtered_peak_freqs.shape[0] * K\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4957e6c-e0cc-4d90-a495-348a8bbab3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "INCREMENT = 5\n",
    "VALUE = 0.05\n",
    "target_rate = 0.7\n",
    "growth_parameter = 0.3\n",
    "\n",
    "bias_scaling = 1\n",
    "input_scaling = 0.1\n",
    "leaky_rate = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a45058f-89f6-4fb3-bfe7-b1799f31614b",
   "metadata": {},
   "source": [
    "### Multivariate matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7fe500-b3fd-46e3-ab6c-1233d8091648",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_bands = np.repeat(filtered_data, K, axis=0)\n",
    "\n",
    "class TwoDimArrayWrapper:\n",
    "    def __init__(self, input_data):\n",
    "        if input_data.ndim != 2:\n",
    "            raise ValueError(\"Expected a 2D array.\")\n",
    "        self.input_data = input_data\n",
    "        self.shape = input_data.shape\n",
    "        self.size = input_data.shape[1]\n",
    "        self.flat_data = input_data.flatten()\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        # Handle single element access\n",
    "        return self.input_data[:, key]\n",
    "        \n",
    "frequency_bands = TwoDimArrayWrapper(frequency_bands)\n",
    "frequency_bands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39af15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import reservoir.reservoir\n",
    "from reservoir.reservoir import update_reservoir\n",
    "from reservoir.reservoir import init_matrices\n",
    "from connexion_generation.utility import compute_synaptic_change\n",
    "from connexion_generation.bounded_adsp import bounded_adsp\n",
    "\n",
    "# Initialisation EE\n",
    "Win_hasp_band, W_hasp_band, bias_hasp_band =  init_matrices(n, 1, 0, seed=SEED)\n",
    "bias_hasp_band = bias_hasp_band*bias_scaling\n",
    "Win_hasp_band = Win_hasp_band*input_scaling\n",
    "\n",
    "def run_HADSP_algorithm(W, Win, bias, input_data, visualize=False):\n",
    "    # last_state\n",
    "    state = np.random.uniform(0, 1, n)\n",
    "    state_history = []\n",
    "    \n",
    "    total_add = 0\n",
    "    total_prun = 0\n",
    "    add = []\n",
    "    prun = []\n",
    "    step=0\n",
    "\n",
    "    for i in range(INCREMENT*5):\n",
    "        state = update_reservoir(W, Win, input_data[i], state, leaky_rate, bias, activation_function)\n",
    "        state_history.append(state)\n",
    "\n",
    "    # size of simulation \n",
    "    number_steps = int((input_data.size-INCREMENT*5)/INCREMENT)\n",
    "    for k in tqdm(range(number_steps)): \n",
    "        delta_z = compute_synaptic_change(state_history[-INCREMENT:], target_rate, growth_parameter, average=\"WHOLE\")\n",
    "        W, _, nb_new_add, nb_new_prun = bounded_adsp(W, state, delta_z, VALUE)\n",
    "    \n",
    "        for i in range(INCREMENT):\n",
    "            state = update_reservoir(W, Win, input_data[INCREMENT*(k+5)+i], state, leaky_rate, bias, activation_function)\n",
    "            state_history.append(state)\n",
    "            \n",
    "        total_add += nb_new_add\n",
    "        total_prun += nb_new_prun\n",
    "        add.append(total_add)\n",
    "        prun.append(total_prun)\n",
    "        step += 1\n",
    "        \n",
    "    add = np.array(add)\n",
    "    prun = np.array(prun)\n",
    "\n",
    "    if visualize:\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(step)*INCREMENT, add, label=\"total number of added connexion\")\n",
    "        plt.plot(np.arange(step)*INCREMENT, prun, label=\"total number of prunned connexion\")\n",
    "        plt.plot(np.arange(step)*INCREMENT, add-prun, label=\"difference\")\n",
    "        plt.plot(np.arange(step)*INCREMENT, [0]*step, linestyle=(0, (1, 10)))\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "    return W\n",
    "\n",
    "W_hasp_band = run_HADSP_algorithm(W_hasp_band, Win_hasp_band, bias_hasp_band, frequency_bands, visualize=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2e2bab4-28b5-44f6-ae65-7eda8a67312f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T23:48:41.233026Z",
     "iopub.status.busy": "2023-07-26T23:48:41.232811Z",
     "iopub.status.idle": "2023-07-26T23:48:41.764399Z",
     "shell.execute_reply": "2023-07-26T23:48:41.763635Z",
     "shell.execute_reply.started": "2023-07-26T23:48:41.233008Z"
    },
    "tags": []
   },
   "source": [
    "heatmap(W_hasp_band.todense(), cmap=color_palette(\"cividis\", as_cmap=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8125ad-e92a-4c6a-94ca-ed2637fefb3b",
   "metadata": {},
   "source": [
    "We create the matrice with same data and same size but randomly generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9bd69b-b6cb-4304-974d-b205cf41003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "connectivity_band =  W_hasp_band.count_nonzero() / (W_hasp_band.shape[0] * W_hasp_band.shape[1])\n",
    "# (hadsp + band)\n",
    "eigen_adsp = sparse.linalg.eigs(W_hasp_band, k=1, which=\"LM\", maxiter=W_hasp_band.shape[0] * 20, tol=0.1, return_eigenvectors=False)\n",
    "sr_adsp = max(abs(eigen_adsp))\n",
    "\n",
    "# 3rd (normal + band)\n",
    "Win_3, W_3, bias_3 =  init_matrices(n, 1, connectivity_band, sr_adsp)\n",
    "bias_3= bias_3*bias_scaling\n",
    "Win_3= Win_3*0.3\n",
    "eigen_3 = sparse.linalg.eigs(W_3, k=1, which=\"LM\", maxiter=W_3.shape[0] * 20, tol=0.1, return_eigenvectors=False)\n",
    "sr_3 = max(abs(eigen_3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9b3d83",
   "metadata": {},
   "source": [
    "### Univariate matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d83057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialisation EE\n",
    "Win_hadsp_uni, W_hadsp_uni, bias_hadsp_uni = init_matrices(n, 1, 0, seed=SEED)\n",
    "bias_hadsp_uni = bias_hadsp_uni*bias_scaling\n",
    "Win_hadsp_uni = Win_hadsp_uni*input_scaling\n",
    "\n",
    "W_hadsp_uni = run_HADSP_algorithm(W_hadsp_uni, Win_hadsp_uni, bias_hadsp_uni, X_pretrain.flatten(), visualize=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57dae01c-110b-4e2c-b6b3-53b8e401934a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T23:48:59.737582Z",
     "iopub.status.busy": "2023-07-26T23:48:59.737356Z",
     "iopub.status.idle": "2023-07-26T23:49:00.279869Z",
     "shell.execute_reply": "2023-07-26T23:49:00.279229Z",
     "shell.execute_reply.started": "2023-07-26T23:48:59.737564Z"
    },
    "tags": []
   },
   "source": [
    "heatmap(W_hadsp_uni.todense(), cmap=color_palette(\"cividis\", as_cmap=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a659faf6",
   "metadata": {},
   "source": [
    "We create Matrices without HADSP (normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802be0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# (normal + random)\n",
    "# We generate a network randomly same connectivity as the HADSP generated one\n",
    "connectivity_hadsp_uni =  W_hadsp_uni.count_nonzero() / (W_hadsp_uni.shape[0] * W_hadsp_uni.shape[1])\n",
    "Win_normal, W_normal, bias_normal =  init_matrices(n, 1, connectivity_hadsp_uni)\n",
    "bias_normal= bias_normal*bias_scaling\n",
    "Win_normal= Win_normal*0.3\n",
    "\n",
    "# Set the input matrices for the two HADSPs\n",
    "#Win_hasp_band = Win_normal\n",
    "#Win_hadsp_multi = Win_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68129bc2-1cc6-4498-9e57-ed18e037643e",
   "metadata": {},
   "source": [
    "## Spectral radius normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf174780-9f9a-48e8-b0e1-5cbecc7dcc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (normal + random)\n",
    "eigen_normal = sparse.linalg.eigs(W_normal, k=1, which=\"LM\", maxiter=W_normal.shape[0] * 20, tol=0.1, return_eigenvectors=False)\n",
    "sr_normal = max(abs(eigen_normal))\n",
    "\n",
    "# 2th  (HADSP + random)\n",
    "eigen_hadsp_uni = sparse.linalg.eigs(W_hadsp_uni, k=1, which=\"LM\", maxiter=W_hadsp_uni.shape[0] * 20, tol=0.1, return_eigenvectors=False)\n",
    "sr_hadsp_uni = max(abs(eigen_hadsp_uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49826ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sr_normal)\n",
    "print(sr_hadsp_uni)\n",
    "print(sr_3)\n",
    "print(sr_adsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a76515-3af0-438e-8098-50ef8745f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral radius normalisation\n",
    "normal_sr = 1.2\n",
    "W_normal = W_normal/sr_normal*normal_sr\n",
    "W_hadsp_uni = W_hadsp_uni/sr_hadsp_uni*normal_sr\n",
    "W_3 = W_3/sr_3*normal_sr\n",
    "W_hasp_band = W_hasp_band/sr_adsp*normal_sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b447f6-e964-4f6c-9116-597cd29c1755",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b3a4e-b06e-450a-b7c5-68802be8013d",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd3250d-e274-4de5-a640-24a14a5108af",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3534f99-25b5-4653-8dcf-7073183e0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want the size of the reservoir to be at least 200\n",
    "caca = []\n",
    "caca_test = []\n",
    "for i in tqdm(range(len(X_train_band))):\n",
    "    #caca.append(np.repeat(X_train[i], K, axis=1))\n",
    "    caca.append(np.repeat(X_train_band[i], K, axis=0).T) # axis still depend of X_train shape\n",
    "for i in tqdm(range(len(X_test_band))):\n",
    "    #caca_test.append(np.repeat(X_test[i], K, axis=1))\n",
    "    caca_test.append(np.repeat(X_test_band[i], K, axis=0).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b9130e-a834-4256-8f29-e42add2eee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reservoirpy.nodes\n",
    "from reservoirpy.nodes import Reservoir, Ridge, Input, ESN\n",
    "reload(reservoirpy.nodes)\n",
    "from scipy.sparse import csr_matrix\n",
    "ridge_coef = 1e-6\n",
    "\n",
    "source = Input()\n",
    "# To remember : \n",
    "#  For reservoirpy   pre_s = W @ r + Win @ (u + noise_gen(dist=dist, shape=u.shape, gain=g_in)) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162262b1-d91b-45b2-8742-dff88b427f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e079dd1d-cf98-426b-ae61-a25fef612f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# Training HADSP + mutlivariate dataset\n",
    "reservoir_hasp_band = Reservoir(units=n, \n",
    "                                W =csr_matrix(W_hasp_band), \n",
    "                                Win=csr_matrix(np.diag(Win_hasp_band.toarray().flatten())), \n",
    "                                bias=csr_matrix(bias_hasp_band).T, \n",
    "                                activation=activation_function,\n",
    "                                equation='external'\n",
    "                               )\n",
    "readout_hasp_band = Ridge(ridge=ridge_coef)\n",
    "model_hasp_band = ESN(reservoir=reservoir_hasp_band, readout=readout_hasp_band)\n",
    "\n",
    "states_train_hasp_band = []\n",
    "def compute_state(x):\n",
    "    return reservoir_hasp_band.run(x, reset=True)[-1, np.newaxis].flatten()\n",
    "\n",
    "states_train_hasp_band = Parallel(n_jobs=N_JOBS)(delayed(compute_state)(x) for x in caca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d83094-95eb-47d2-b7e0-d14be4cd6326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training random + mutlivariate dataset\n",
    "reservoir_3 = Reservoir(units=n, \n",
    "                        W =csr_matrix(W_3), \n",
    "                        Win=csr_matrix(np.diag(Win_3.toarray().flatten())), \n",
    "                        bias=csr_matrix(bias_3).T, \n",
    "                        activation=activation_function,\n",
    "                        equation='external'\n",
    "                       )\n",
    "readout_3 = Ridge(ridge=ridge_coef)\n",
    "model_3 = ESN(reservoir=reservoir_3, readout=readout_3)\n",
    "\n",
    "states_train_3 = []\n",
    "\n",
    "def compute_state(x):\n",
    "    return reservoir_3.run(x, reset=True)[-1, np.newaxis].flatten()\n",
    "\n",
    "states_train_3 = Parallel(n_jobs=N_JOBS)(delayed(compute_state)(x) for x in caca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd4e1b-4d77-4c09-b17c-36a3c3729a3b",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df7178-073b-4903-9772-3adab4251782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#readout_hasp_band.fit(states_train_hasp_band, Y_train)\n",
    "readout_hasp_band.fit(np.array(states_train_hasp_band), Y_train)\n",
    "\n",
    "Y_pred_hasp_band = []\n",
    "def predict(x):\n",
    "    states = reservoir_hasp_band.run(x, reset=True)\n",
    "    y = readout_hasp_band.run(states[-1, np.newaxis])\n",
    "    return y\n",
    "\n",
    "Y_pred_hasp_band = Parallel(n_jobs=N_JOBS)(delayed(predict)(x) for x in caca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e9528-52db-48fb-82f0-29d5d39bded2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#readout_3.fit(states_train_3, Y_train)\n",
    "readout_3.fit(np.array(states_train_3), Y_train)\n",
    "\n",
    "\n",
    "Y_pred_3 = []\n",
    "def predict(x):\n",
    "    states = reservoir_3.run(x, reset=True)\n",
    "    y = readout_3.run(states[-1, np.newaxis])\n",
    "    return y\n",
    "\n",
    "Y_pred_3 = Parallel(n_jobs=N_JOBS)(delayed(predict)(x) for x in caca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3dc743-36c8-4821-948d-f14f43af8104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Y_pred_class = [np.argmax(y_p) for y_p in Y_pred_hasp_band]\n",
    "Y_test_class = [np.argmax(y_t) for y_t in Y_test]\n",
    "\n",
    "score = accuracy_score(Y_test_class, Y_pred_class)\n",
    "\n",
    "print(\"Accuracy for HADSP multi: \", f\"{score * 100:.3f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1522427-59fe-4179-9d99-c9a8046fe867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Y_pred_class = [np.argmax(y_p) for y_p in Y_pred_3]\n",
    "Y_test_class = [np.argmax(y_t) for y_t in Y_test]\n",
    "\n",
    "score = accuracy_score(Y_test_class, Y_pred_class)\n",
    "\n",
    "print(\"Accuracy for random multi: \", f\"{score * 100:.3f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5f3553-1d28-4340-b4b9-f3dc673bdcac",
   "metadata": {},
   "source": [
    "## Classification for univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b79a65-f690-4cc7-8f9f-1d8dd1722d68",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db50e2ca-93d7-48bb-bcff-4f885e8d5a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the arrays\n",
    "\n",
    "pipi = []\n",
    "pipi_test = []\n",
    "\n",
    "for i in tqdm(range(len(X_train))):\n",
    "    pipi.append(np.repeat(X_train[i], n, axis=1))\n",
    "    #pipi.append(np.repeat(X_train[i], n, axis=0).T) # axis still depend of X_train shape\n",
    "    \n",
    "for i in tqdm(range(len(X_test))):\n",
    "    pipi_test.append(np.repeat(X_test[i], n, axis=1))\n",
    "    #pipi_test.append(np.repeat(X_test[i], n, axis=0).T)\n",
    "    \n",
    "pipi[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d940bd76-1473-4dad-9d2e-3d98d7411ee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training HADSP + univariate dataset\n",
    "reservoir_hadsp_uni = Reservoir(units=n, \n",
    "                                W =csr_matrix(W_hadsp_uni), \n",
    "                                Win=csr_matrix(np.diag(Win_hadsp_uni.toarray().flatten())), \n",
    "                                bias=csr_matrix(bias_hadsp_uni).T, \n",
    "                                activation=activation_function,\n",
    "                                equation='external'\n",
    "                               )\n",
    "readout_hadsp_uni = Ridge(ridge=ridge_coef)\n",
    "model_hadsp_uni = ESN(reservoir=reservoir_hadsp_uni, readout=readout_hadsp_uni)\n",
    "\n",
    "\n",
    "states_train_hadsp_uni = []\n",
    "\n",
    "def compute_state(x):\n",
    "    return reservoir_hadsp_uni.run(x, reset=True)[-1, np.newaxis].flatten()\n",
    "\n",
    "states_train_hadsp_uni = Parallel(n_jobs=N_JOBS)(delayed(compute_state)(x) for x in pipi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dedf77f-c151-43b0-93b2-972373d18bae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training HADSP + univariate dataset\n",
    "reservoir_normal = Reservoir(units=n, \n",
    "                                W =csr_matrix(W_normal), \n",
    "                                Win=csr_matrix(np.diag(Win_normal.toarray().flatten())), \n",
    "                                bias=csr_matrix(bias_normal).T, \n",
    "                                activation=activation_function,\n",
    "                                equation='external'\n",
    "                               )\n",
    "readout_normal = Ridge(ridge=ridge_coef)\n",
    "model_normal = ESN(reservoir=reservoir_normal, readout=readout_normal)\n",
    "\n",
    "\n",
    "states_train_normal = []\n",
    "\n",
    "def compute_state(x):\n",
    "    return reservoir_normal.run(x, reset=True)[-1, np.newaxis].flatten()\n",
    "\n",
    "states_train_normal = Parallel(n_jobs=N_JOBS)(delayed(compute_state)(x) for x in pipi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb1f90-b6e4-4e36-a860-bef3b67289c1",
   "metadata": {},
   "source": [
    "### Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0dd888-95ce-463b-b240-8275ab9de735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#readout_hasp_uni.fit(states_train_hasp_uni, Y_train)\n",
    "readout_hadsp_uni.fit(np.array(states_train_hadsp_uni), Y_train)\n",
    "\n",
    "Y_pred_hadsp_uni = []\n",
    "\n",
    "def predict(x):\n",
    "    states = reservoir_hadsp_uni.run(x, reset=True)\n",
    "    y = readout_hadsp_uni.run(states[-1, np.newaxis])\n",
    "    return y\n",
    "\n",
    "Y_pred_hadsp_uni = Parallel(n_jobs=N_JOBS)(delayed(predict)(x) for x in pipi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932afcd-6567-42e1-b1d8-83669e3713c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#readout_normal.fit(states_train_normal, Y_train)\n",
    "readout_normal.fit(np.array(states_train_normal), Y_train)\n",
    "\n",
    "Y_pred_normal = []\n",
    "\n",
    "def predict(x):\n",
    "    states = reservoir_normal.run(x, reset=True)\n",
    "    y = readout_normal.run(states[-1, np.newaxis])\n",
    "    return y\n",
    "\n",
    "Y_pred_normal = Parallel(n_jobs=N_JOBS)(delayed(predict)(x) for x in pipi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f4028-f457-46b4-a219-7f5fed575af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Y_pred_class = [np.argmax(y_p) for y_p in Y_pred_hadsp_uni]\n",
    "Y_test_class = [np.argmax(y_t) for y_t in Y_test]\n",
    "\n",
    "score = accuracy_score(Y_test_class, Y_pred_class)\n",
    "\n",
    "print(\"Accuracy for HADSP uni: \", f\"{score * 100:.3f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec046d-5c1e-4f04-82bd-668bd24f79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Y_pred_class = [np.argmax(y_p) for y_p in Y_pred_normal]\n",
    "Y_test_class = [np.argmax(y_t) for y_t in Y_test]\n",
    "\n",
    "score = accuracy_score(Y_test_class, Y_pred_class)\n",
    "\n",
    "print(\"Accuracy for random uni: \", f\"{score * 100:.3f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3525c31-24fc-450e-8a17-f5801e42e37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e97b50-735c-4413-a7bf-e136679d53fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f56088-dfe1-4646-a413-87108460cfdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79b55e-ab4b-4f76-9e71-5f4274666e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26155189-0804-473d-b69d-1c80b40bd2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f621a-c8db-4b6e-92ff-d9e1c9ef9e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688bdf0b-2ad2-4526-b259-7b50c77dfe09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fdd05f-9f17-4222-a077-8236c0e7bd98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dc7ab1a-e020-489a-8ff9-9bbd689de15e",
   "metadata": {},
   "source": [
    "## Prediction ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bcdbf",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15374eac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import reservoir.reservoir\n",
    "from reservoir.reservoir import train_ei, train\n",
    "reload(reservoir.reservoir)\n",
    "\n",
    "ridge_coef = 1e-7\n",
    "step_ahead = 30\n",
    "\n",
    "# To remember\n",
    "np.zeros(2000)\n",
    "\n",
    "print(frequency_bands.shape)\n",
    "print(input_data.shape)\n",
    "# to generate the evaluation dataset\n",
    "START_EVAL_STEP = 3000\n",
    "x_train_bands = frequency_bands[:,:START_EVAL_STEP]\n",
    "x_train_normal = input_data[:START_EVAL_STEP]\n",
    "y_train = input_data[step_ahead:START_EVAL_STEP+step_ahead]\n",
    "\n",
    "# Training random + MG\n",
    "Wout_normal, b_out_normal, last_state_normal = train(W_normal, Win_normal, bias_normal, x_train_normal, y_train, activation_function, ridge_coef = ridge_coef)\n",
    "\n",
    "# Training for HADSP + MG\n",
    "Wout_hadsp_multi, b_out_hadsp_multi, last_state_hadsp_multi = train(W_hadsp_multi, Win_hadsp_multi, bias_hadsp_multi, x_train_normal, y_train, activation_function, ridge_coef = ridge_coef)\n",
    "\n",
    "# Training random + bandfilter\n",
    "Wout_3, b_out_3, last_state_3 = train(W_3, Win_3, bias_3, x_train_bands, y_train, activation_function, ridge_coef = ridge_coef)\n",
    "\n",
    "# Training output HASDP + bandfilter\n",
    "Wout_hasp_band, b_out_hasp_band, last_state_hasp_band = train(W_hasp_band, Win_hasp_band, bias_hasp_band, x_train_bands, y_train, activation_function, ridge_coef = ridge_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fcfe07-1ad0-4d8f-827f-bb9776e8086e",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65dac84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from reservoir.reservoir import run\n",
    "reload(reservoir.reservoir)\n",
    "from reservoir.reservoirpy_util import plot_results, plot_readout\n",
    "\n",
    "\n",
    "ending_eval_step = 4900\n",
    "x_eval_bands = frequency_bands[:,START_EVAL_STEP:ending_eval_step]\n",
    "x_eval_normal = input_data[START_EVAL_STEP:ending_eval_step]\n",
    "y_target = input_data[START_EVAL_STEP + step_ahead :ending_eval_step + step_ahead]\n",
    "\n",
    "# Prediction for random + MG\n",
    "y_pred_normal = run(W_normal, Win_normal, bias_normal, Wout_normal, x_eval_normal, activation_function, b_out_normal, last_state_normal)\n",
    "\n",
    "# Prediction for HADSP + MG\n",
    "y_pred_hadsp_multi = run(W_hadsp_multi, Win_hadsp_multi, bias_hadsp_multi, Wout_hadsp_multi, x_eval_normal, activation_function, b_out_hadsp_multi, last_state_hadsp_multi)\n",
    "\n",
    "# Prediction for random + bandfilter\n",
    "y_pred_3 = run(W_3, Win_3, bias_3, Wout_3, x_eval_bands, activation_function, b_out_3, last_state_3)\n",
    "\n",
    "# Prediction for HADSP + bandfilter\n",
    "y_pred_hasp_band = run(W_hasp_band, Win_hasp_band, bias_hasp_band, Wout_hasp_band, x_eval_bands, activation_function, b_out_hasp_band, last_state_hasp_band)\n",
    "\n",
    "\n",
    "plot_results(y_pred_3, y_target, sample=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61165568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import reservoir.losses\n",
    "from reservoir.losses import rmse, nrmse\n",
    "reload(reservoir.losses)\n",
    "\n",
    "print(\"nrmse normal        :\", float(nrmse(y_target[:300], y_pred_normal[:300])))\n",
    "print(\"nrmse hadsp     :\", float(nrmse(y_target[:300], y_pred_hadsp_multi[:300])))\n",
    "print(\"nrmse random + band :\", float(nrmse(y_target[:300], y_pred_3[:300])))\n",
    "print(\"nrmse hadsp + band   :\", float(nrmse(y_target[:300], y_pred_hasp_band[:300])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c77a0-5d0d-4dbf-b184-c46f6b1c3781",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_hadsp_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc19b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nrmse_array_normal = []\n",
    "nrmse_array_hadsp_multi = []\n",
    "nrmse_array_3 = []\n",
    "nrmse_array_mg = []\n",
    "\n",
    "for i in range(len(y_target)-100- step_ahead):\n",
    "    y_target_i = y_target[i:100+i]\n",
    "    nrmse_array_normal.append(nrmse(y_target_i, y_pred_normal[i:100+i]))\n",
    "    nrmse_array_hadsp_multi.append(nrmse(y_target_i, y_pred_hadsp_multi[i:100+i]))\n",
    "    nrmse_array_3.append(nrmse(y_target_i, y_pred_3[i:100+i]))\n",
    "    nrmse_array_mg.append(nrmse(y_target_i, y_pred_hasp_band[i:100+i]))\n",
    "    \n",
    "log10_nrmse_normal = np.log10(nrmse_array_normal)\n",
    "log10_nrmse_hadsp_multi = np.log10(nrmse_array_hadsp_multi)\n",
    "log10_nrmse_3 = np.log10(nrmse_array_3)\n",
    "log10_nrmse_mg = np.log10(nrmse_array_mg)\n",
    "plt.figure()\n",
    "plt.plot(log10_nrmse_normal[:1000])\n",
    "plt.plot(log10_nrmse_hadsp_multi[:1000])\n",
    "plt.plot(log10_nrmse_3[:1000])\n",
    "plt.plot(log10_nrmse_mg[:1000])\n",
    "\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Log10 NRMSE')\n",
    "plt.legend([\"HADSP+band\", \"random\", \" random + bandfilter\", \"HADSP\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b27da37",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations, permutations\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def plot_connectivity(coo):\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Convert coo_matrix to edge list and add edges to the graph\n",
    "    for node1, node2 in zip(coo.row, coo.col):\n",
    "        G.add_edge(node1, node2)\n",
    "\n",
    "    triad_connections = defaultdict(int)\n",
    "\n",
    "    # Get all sets of 3 nodes\n",
    "    for nodes in combinations(G.nodes, 3):\n",
    "        # For each node in the triad, count its incoming and outgoing connections within the triad\n",
    "        connectivity_states = []\n",
    "        for node in nodes:\n",
    "            in_edges = sum([G.has_edge(other, node) for other in nodes if other != node])\n",
    "            out_edges = sum([G.has_edge(node, other) for other in nodes if other != node])\n",
    "            connectivity_states.append((in_edges, out_edges))\n",
    "        # Sort the connectivity states so that equivalent triads have the same key, regardless of node order\n",
    "        connectivity_states = tuple(sorted(connectivity_states))\n",
    "        triad_connections[connectivity_states] += 1\n",
    "\n",
    "    # Sort results by total number of connections\n",
    "    sorted_results = sorted(((sum(in_edges for in_edges, out_edges in key) + sum(out_edges for in_edges, out_edges in key), key) for key in triad_connections.items()), key=lambda x: x[0])\n",
    "    sorted_labels = [str(key) for total, key in sorted_results]\n",
    "    sorted_values = [triad_connections[key] for total, key in sorted_results]\n",
    "\n",
    "    # Plot results\n",
    "    plt.bar(range(len(sorted_labels)), sorted_values, tick_label=sorted_labels)\n",
    "    plt.xlabel('Triad connectivity state')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Triad Connection Count in Graph')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_connectivity(W_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2619596",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_connectivity(W_hasp_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f87de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = filtered_data\n",
    "# Create a matrix to hold the mutual information between each pair of time series\n",
    "mi_matrix = np.zeros((len(time_series), len(time_series)))\n",
    "\n",
    "    \n",
    "# Function to compute mutual information\n",
    "def compute_mi(i, j):\n",
    "    # Discretize the data\n",
    "    time_series_i_discrete = np.floor(time_series[i] * 10).astype(int)\n",
    "    time_series_j_discrete = np.floor(time_series[j] * 10).astype(int)\n",
    "    \n",
    "    # Compute mutual information\n",
    "    mi = mutual_info_score(time_series_i_discrete, time_series_j_discrete)\n",
    "    \n",
    "    return i, j, mi\n",
    "\n",
    "# Create a list of all pairs of indices\n",
    "indices = [(i, j) for i in range(len(time_series)) for j in range(i, len(time_series))]\n",
    "\n",
    "\n",
    "\n",
    "# Use joblib to parallelize the computation\n",
    "results = Parallel(n_jobs=-1, backend=\"threading\", verbose=1)(delayed(compute_mi)(i, j) for i, j in indices)\n",
    "\n",
    "# Store the results in the matrix\n",
    "for i, j, mi in results:\n",
    "    mi_matrix[i, j] = mi\n",
    "    mi_matrix[j, i] = mi\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "heatmap(mi_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcf94f2-8b61-4263-8ee6-71b8a1f93068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dbe724-3eb9-4fb8-8135-1481d07787c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339f7f3e-7a1b-4fee-818e-70c83f006eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec966dd-117a-4e0f-8ac7-4f274e5157de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a567fe1b-db79-44d1-abd8-88d7cee34441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd657f-d0fe-42b5-a3c1-c0d5db353913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2478c-bb79-4bc0-855f-b028109c8022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf0ae95-2438-4b45-8abd-4614e0281439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HADSP_env",
   "language": "python",
   "name": "hadsp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
