{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f790cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T13:07:50.832654Z",
     "iopub.status.busy": "2024-07-08T13:07:50.831850Z",
     "iopub.status.idle": "2024-07-08T13:07:51.211448Z",
     "shell.execute_reply": "2024-07-08T13:07:51.211188Z",
     "shell.execute_reply.started": "2024-07-08T13:07:50.832601Z"
    },
    "jupyter": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "SEED = 923984"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb44384e-7cbc-4611-a015-e1c073f61aa9",
   "metadata": {},
   "source": [
    "# Datasets loading\n",
    "\n",
    "Lots of different on availabale : https://towardsdatascience.com/a-data-lakes-worth-of-audio-datasets-b45b88cd4ad\n",
    "\n",
    "Classification: \n",
    "https://arxiv.org/abs/1803.07870\n",
    "\n",
    "https://github.com/FilippoMB/Time-series-classification-and-clustering-with-Reservoir-Computing\n",
    "\n",
    "Multivariate:\n",
    "https://www.timeseriesclassification.com/dataset.php"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b2d29d-7fff-4032-8b36-559c722818b8",
   "metadata": {},
   "source": [
    "## Aeon"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11d0e556-efa5-4132-8444-6e5792650331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T12:02:08.057574Z",
     "iopub.status.busy": "2024-07-07T12:02:08.057423Z",
     "iopub.status.idle": "2024-07-07T12:02:09.163006Z",
     "shell.execute_reply": "2024-07-07T12:02:09.162638Z",
     "shell.execute_reply.started": "2024-07-07T12:02:08.057567Z"
    }
   },
   "source": [
    "from aeon.datasets import load_classification\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "dataset_name = \"SpokenArabicDigits\"\n",
    "\n",
    "X_train_unprocessed, Y_train_raw, meta_data = load_classification(dataset_name, return_metadata=True, load_equal_length = False, split=\"train\")\n",
    "X_test_unprocessed, Y_test_raw, meta_data = load_classification(dataset_name, return_metadata=True, load_equal_length = False, split=\"test\")\n",
    "\n",
    "is_instances_classification = True\n",
    "sampling_rate = 10000\n",
    "\n",
    "groups = None\n",
    "\n",
    "X_train_raw = []\n",
    "for x in X_train_unprocessed:\n",
    "    X_train_raw.append(x.T)\n",
    "\n",
    "X_test_raw = []\n",
    "for x in X_test_unprocessed:\n",
    "    X_test_raw.append(x.T)\n",
    "\n",
    "if X_train_raw[0].shape[1] == 1:\n",
    "    is_multivariate = False\n",
    "else:\n",
    "    is_multivariate = True\n",
    "\n",
    "print(\" Number of instances = \", len(X_train_raw))\n",
    "print(\" Shape of X = \", X_train_raw[0].shape)\n",
    "print(\" Shape of y = \", Y_train_raw.shape)\n",
    "\n",
    "print(\" Meta data = \", meta_data)\n",
    "print(\"Multivariate = \", is_multivariate)\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y_train_raw = le.fit_transform(Y_train_raw).reshape(-1, 1)\n",
    "Y_test = le.transform(Y_test_raw).reshape(-1, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "Y_train_raw = ohe.fit_transform(Y_train_raw.reshape(-1, 1))\n",
    "Y_test = ohe.transform(Y_test.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb81c7-9923-4fee-a6ed-98a84b3b7b6f",
   "metadata": {},
   "source": [
    "## Torchaudio\n",
    "\n",
    "https://pytorch.org/audio/stable/datasets.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1c1892-d386-4a4a-ac2e-acf0162c0b38",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-08T13:07:51.212570Z",
     "iopub.status.busy": "2024-07-08T13:07:51.212344Z",
     "iopub.status.idle": "2024-07-08T13:09:00.139881Z",
     "shell.execute_reply": "2024-07-08T13:09:00.139209Z",
     "shell.execute_reply.started": "2024-07-08T13:07:51.212561Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m sampling_rate \u001b[38;5;241m=\u001b[39m dataset_train[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m dataset \u001b[38;5;241m=\u001b[39m ConcatDataset([dataset_train, dataset_val])\n\u001b[0;32m---> 16\u001b[0m X_train_raw \u001b[38;5;241m=\u001b[39m [sample[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[1;32m     17\u001b[0m Y_train_raw \u001b[38;5;241m=\u001b[39m [sample[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[1;32m     19\u001b[0m is_multivariate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m sampling_rate \u001b[38;5;241m=\u001b[39m dataset_train[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m dataset \u001b[38;5;241m=\u001b[39m ConcatDataset([dataset_train, dataset_val])\n\u001b[0;32m---> 16\u001b[0m X_train_raw \u001b[38;5;241m=\u001b[39m [sample[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[1;32m     17\u001b[0m Y_train_raw \u001b[38;5;241m=\u001b[39m [sample[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[1;32m     19\u001b[0m is_multivariate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/hadsp_env/lib/python3.11/site-packages/torch/utils/data/dataset.py:335\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets[dataset_idx][sample_idx]\n",
      "File \u001b[0;32m~/miniforge3/envs/hadsp_env/lib/python3.11/site-packages/torchaudio/datasets/speechcommands.py:179\u001b[0m, in \u001b[0;36mSPEECHCOMMANDS.__getitem__\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the n-th sample from the dataset.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m        Utterance number\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    178\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_metadata(n)\n\u001b[0;32m--> 179\u001b[0m waveform \u001b[38;5;241m=\u001b[39m _load_waveform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_archive, metadata[\u001b[38;5;241m0\u001b[39m], metadata[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (waveform,) \u001b[38;5;241m+\u001b[39m metadata[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/miniforge3/envs/hadsp_env/lib/python3.11/site-packages/torchaudio/datasets/utils.py:51\u001b[0m, in \u001b[0;36m_load_waveform\u001b[0;34m(root, filename, exp_sample_rate)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_waveform\u001b[39m(\n\u001b[1;32m     46\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     47\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     48\u001b[0m     exp_sample_rate: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     49\u001b[0m ):\n\u001b[1;32m     50\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, filename)\n\u001b[0;32m---> 51\u001b[0m     waveform, sample_rate \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(path)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exp_sample_rate \u001b[38;5;241m!=\u001b[39m sample_rate:\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample rate should be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_sample_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/hadsp_env/lib/python3.11/site-packages/torchaudio/_backend/utils.py:205\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mload(uri, frame_offset, num_frames, normalize, channels_first, \u001b[38;5;28mformat\u001b[39m, buffer_size)\n",
      "File \u001b[0;32m~/miniforge3/envs/hadsp_env/lib/python3.11/site-packages/torchaudio/_backend/ffmpeg.py:297\u001b[0m, in \u001b[0;36mFFmpegBackend.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m    289\u001b[0m     uri: InputType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m     buffer_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m,\n\u001b[1;32m    296\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_audio(uri, frame_offset, num_frames, normalize, channels_first, \u001b[38;5;28mformat\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/hadsp_env/lib/python3.11/site-packages/torchaudio/_backend/ffmpeg.py:91\u001b[0m, in \u001b[0;36mload_audio\u001b[0;34m(src, frame_offset, num_frames, convert, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m     89\u001b[0m sample_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(s\u001b[38;5;241m.\u001b[39mget_src_stream_info(s\u001b[38;5;241m.\u001b[39mdefault_audio_stream)\u001b[38;5;241m.\u001b[39msample_rate)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;241m=\u001b[39m _get_load_filter(frame_offset, num_frames, convert)\n\u001b[0;32m---> 91\u001b[0m waveform \u001b[38;5;241m=\u001b[39m _load_audio(s, \u001b[38;5;28mfilter\u001b[39m, channels_first)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m waveform, sample_rate\n",
      "File \u001b[0;32m~/miniforge3/envs/hadsp_env/lib/python3.11/site-packages/torchaudio/_backend/ffmpeg.py:68\u001b[0m, in \u001b[0;36m_load_audio\u001b[0;34m(s, filter, channels_first)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_audio\u001b[39m(\n\u001b[1;32m     64\u001b[0m     s: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchaudio.io.StreamReader\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mfilter\u001b[39m: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     66\u001b[0m     channels_first: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     67\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 68\u001b[0m     s\u001b[38;5;241m.\u001b[39madd_audio_stream(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, filter_desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m)\n\u001b[1;32m     69\u001b[0m     s\u001b[38;5;241m.\u001b[39mprocess_all_packets()\n\u001b[1;32m     70\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mpop_chunks()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/hadsp_env/lib/python3.11/site-packages/torio/io/_streaming_media_decoder.py:778\u001b[0m, in \u001b[0;36mStreamingMediaDecoder.add_audio_stream\u001b[0;34m(self, frames_per_chunk, buffer_chunk_size, stream_index, decoder, decoder_option, filter_desc)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere is no audio stream.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 778\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_be\u001b[38;5;241m.\u001b[39madd_audio_stream(\n\u001b[1;32m    779\u001b[0m     i,\n\u001b[1;32m    780\u001b[0m     frames_per_chunk,\n\u001b[1;32m    781\u001b[0m     buffer_chunk_size,\n\u001b[1;32m    782\u001b[0m     filter_desc,\n\u001b[1;32m    783\u001b[0m     decoder,\n\u001b[1;32m    784\u001b[0m     decoder_option \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    785\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load dataset using torchaudio\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torchaudio.datasets import VoxCeleb1Identification, SPEECHCOMMANDS\n",
    "from torch.utils.data import ConcatDataset, random_split, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "dataset_name = \"SPEECHCOMMANDS\"\n",
    "\n",
    "dataset_train = SPEECHCOMMANDS(root=\"datasets/\", download=True, subset=\"training\")\n",
    "dataset_val = SPEECHCOMMANDS(root=\"datasets/\", download=True, subset=\"validation\")\n",
    "\n",
    "sampling_rate = dataset_train[0][1]\n",
    "\n",
    "dataset = ConcatDataset([dataset_train, dataset_val])\n",
    "\n",
    "X_train_raw = [sample[0][0].numpy().reshape(-1, 1) for sample in dataset]\n",
    "Y_train_raw = [sample[2] for sample in dataset]\n",
    "\n",
    "is_multivariate = False\n",
    "\n",
    "groups = None\n",
    "\n",
    "is_instances_classification = True\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y_train_raw = le.fit_transform(Y_train_raw).reshape(-1, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "Y_train_raw = ohe.fit_transform(Y_train_raw.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d6272-708d-4709-8e35-5a84268bed64",
   "metadata": {},
   "source": [
    "## Prediction ahead\n",
    "\n",
    "Datasets available :\n",
    "\n",
    "* MackeyGlass\n",
    "* Lorenz"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9863f61-12b5-45a8-bbb0-4531fc27a6cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-24T06:31:21.296121Z",
     "iopub.status.busy": "2024-06-24T06:31:21.296005Z",
     "iopub.status.idle": "2024-06-24T06:31:22.902202Z",
     "shell.execute_reply": "2024-06-24T06:31:22.901859Z",
     "shell.execute_reply.started": "2024-06-24T06:31:21.296112Z"
    },
    "scrolled": true
   },
   "source": [
    "from datasets.load_datasets import load_dataset_prediction\n",
    "is_instances_classification = False\n",
    "dataset_name = \"MackeyGlass\"\n",
    "step_ahead=5\n",
    "\n",
    "is_multivariate, sampling_rate, X_train_raw, X_test_raw, Y_train_raw, Y_test = load_dataset_prediction(dataset_name, step_ahead, visualize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b219b-eb64-4715-b983-7de3c392f088",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Classification\n",
    "\n",
    "Datasets available :\n",
    "\n",
    "* FSDD\n",
    "* HAART\n",
    "* JapaneseVowels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1426fece-a207-4fb2-89d6-2637b610ba68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:55:07.187815Z",
     "iopub.status.busy": "2024-07-06T12:55:07.187541Z",
     "iopub.status.idle": "2024-07-06T12:55:08.468570Z",
     "shell.execute_reply": "2024-07-06T12:55:08.468190Z",
     "shell.execute_reply.started": "2024-07-06T12:55:07.187802Z"
    }
   },
   "source": [
    "from datasets.load_datasets import load_dataset_classification\n",
    "is_instances_classification = True\n",
    "dataset_name = \"JapaneseVowels\"\n",
    "\n",
    "is_multivariate, sampling_rate, X_train_raw, X_test_raw, Y_train_raw, Y_test, groups = load_dataset_classification(dataset_name, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86961904-ad36-4af8-ad21-6d51f491da61",
   "metadata": {},
   "source": [
    "# Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a38d2df41a727",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-07-08T13:09:00.140091Z",
     "iopub.status.idle": "2024-07-08T13:09:00.140190Z",
     "shell.execute_reply": "2024-07-08T13:09:00.140139Z",
     "shell.execute_reply.started": "2024-07-08T13:09:00.140134Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from reservoir.activation_functions import tanh, heaviside, sigmoid\n",
    "\n",
    "# the activation function choosen for the rest of the experiment\n",
    "# activation_function = lambda x : sigmoid(2*(x-0.5))tanh(x)\n",
    "activation_function = lambda x : tanh(x)\n",
    "\n",
    "plt.plot(np.linspace(0, 3, 100), activation_function(np.linspace(0, 3, 100)))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f892fb1cccd7511",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca76d0e06f936c",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-07-08T13:09:00.140642Z",
     "iopub.status.idle": "2024-07-08T13:09:00.140756Z",
     "shell.execute_reply": "2024-07-08T13:09:00.140698Z",
     "shell.execute_reply.started": "2024-07-08T13:09:00.140694Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import math \n",
    " \n",
    "# Cross validation\n",
    "from sklearn.model_selection import StratifiedKFold, TimeSeriesSplit, StratifiedGroupKFold\n",
    "from datasets.preprocessing import flexible_indexing\n",
    "\n",
    "#Preprocessing\n",
    "from datasets.multivariate_generation import generate_multivariate_dataset, extract_peak_frequencies\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datasets.preprocessing import scale_data\n",
    "from datasets.preprocessing import add_noise, duplicate_data\n",
    "\n",
    "# Define noise parameter\n",
    "noise_std = 0.001\n",
    "\n",
    "\n",
    "nb_splits=3\n",
    "if is_instances_classification:\n",
    "    if groups is None:\n",
    "        splits = StratifiedKFold(n_splits=nb_splits, shuffle=True, random_state=SEED).split(X_train_raw, np.argmax(Y_train_raw, axis=1))\n",
    "    else:\n",
    "        splits = StratifiedGroupKFold(n_splits=nb_splits, shuffle=True, random_state=SEED).split(X_train_raw, np.argmax(Y_train_raw, axis=1), groups)\n",
    "else: #prediction\n",
    "    splits = TimeSeriesSplit(n_splits=nb_splits).split(X_train_raw)\n",
    "\n",
    "X_pretrain = []\n",
    "X_pretrain_noisy  = []\n",
    "X_train = []\n",
    "X_train_noisy = []\n",
    "X_val = []\n",
    "X_val_noisy = []\n",
    "X_pretrain_band = []\n",
    "X_pretrain_band_noisy = []\n",
    "X_train_band = []\n",
    "X_train_band_noisy = []\n",
    "X_val_band = []\n",
    "X_val_band_noisy = []\n",
    "\n",
    "Y_train = []\n",
    "Y_val = []\n",
    "\n",
    "WINDOW_LENGTH = 10\n",
    "freq_train_data = X_train_raw\n",
    "flat_train_data = np.concatenate(freq_train_data, axis=0) if is_instances_classification else freq_train_data\n",
    "extract_peak_frequencies(flat_train_data, sampling_rate, smooth=True, window_length=WINDOW_LENGTH, threshold=1e-5, nperseg=1024, visualize=True)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(splits):\n",
    "    x_train = flexible_indexing(X_train_raw, train_index)\n",
    "    x_val = flexible_indexing(X_train_raw, val_index)\n",
    "    Y_train.append(flexible_indexing(Y_train_raw, train_index))\n",
    "    Y_val.append(flexible_indexing(Y_train_raw, val_index))\n",
    "    # SPLITS\n",
    "    if is_multivariate:\n",
    "        x_train_band, x_val_band = x_train, x_val\n",
    "        del x_train, x_val\n",
    "\n",
    "        \n",
    "    # PREPROCESSING        \n",
    "    freq_train_data = x_train_band if is_multivariate else x_train\n",
    "    flat_train_data = np.concatenate(freq_train_data, axis=0) if is_instances_classification else freq_train_data\n",
    "    filtered_peak_freqs = extract_peak_frequencies(flat_train_data, sampling_rate, smooth=True, window_length=WINDOW_LENGTH, threshold=1e-5, nperseg=1024, visualize=False)\n",
    "    \n",
    "    if not is_multivariate:\n",
    "        common_size = len(filtered_peak_freqs)\n",
    "        x_train_band = generate_multivariate_dataset(\n",
    "            filtered_peak_freqs, x_train, sampling_rate, is_instances_classification, nb_jobs=-1, spectral_representation=\"stft\", hop=100\n",
    "        )\n",
    "        x_val_band = generate_multivariate_dataset(\n",
    "            filtered_peak_freqs, x_val, sampling_rate, is_instances_classification, nb_jobs=-1, spectral_representation=\"stft\", hop=100\n",
    "        )\n",
    "\n",
    "    if not is_multivariate:\n",
    "        scaler_x_uni = MinMaxScaler(feature_range=(0, 1))\n",
    "        x_train, x_val, _ = scale_data(x_train, x_val, None, scaler_x_uni, is_instances_classification)       \n",
    "        X_train.append(x_train)\n",
    "        X_val.append(x_val)\n",
    "\n",
    "    scaler_multi = MinMaxScaler(feature_range=(0, 1))\n",
    "    x_train_band, x_val_band, _ = scale_data(x_train_band, x_val_band, None, scaler_multi, is_instances_classification)\n",
    "    X_train_band.append(x_train_band)\n",
    "    X_val_band.append(x_val_band)\n",
    "             \n",
    "    #Train/Val/Test\n",
    "    if is_instances_classification:\n",
    "        # NOISE\n",
    "        # UNI\n",
    "        if not is_multivariate:\n",
    "            x_train_noisy=[add_noise(instance, noise_std) for instance in x_train]\n",
    "            X_train_noisy.append([add_noise(instance, noise_std) for instance in x_train])\n",
    "            X_val_noisy.append([add_noise(instance, noise_std) for instance in x_val])\n",
    "            \n",
    "        # MULTI\n",
    "        x_train_band_noisy=[add_noise(instance, noise_std) for instance in x_train_band]\n",
    "        X_train_band_noisy.append(x_train_band_noisy)\n",
    "        X_val_band_noisy.append([add_noise(instance, noise_std) for instance in x_val_band])\n",
    "    \n",
    "    else:  #if prediction\n",
    "        # NOISE\n",
    "        # UNI\n",
    "        if not is_multivariate:\n",
    "            x_train_noisy=add_noise(x_train, noise_std)\n",
    "            X_train_noisy.append(x_train_noisy)\n",
    "            X_val_noisy.append(add_noise(x_val, noise_std))\n",
    "    \n",
    "        # MULTI\n",
    "        x_train_band_noisy=add_noise(x_train_band, noise_std)\n",
    "        X_train_band_noisy.append(x_train_band_noisy)\n",
    "        X_val_band_noisy.append(add_noise(x_val_band, noise_std))\n",
    "\n",
    "    # Define the number of instances you want to select\n",
    "    x_size = len(x_train_band) if is_multivariate else len(x_train)\n",
    "    num_samples_for_pretrain = 500 if x_size >= 500 else x_size\n",
    "    random_indices = np.random.choice(x_size, num_samples_for_pretrain, replace=False)\n",
    "\n",
    "    # Defining pretrain   \n",
    "    if not is_multivariate:\n",
    "        X_pretrain.append(np.array(x_train)[random_indices].flatten())\n",
    "        X_pretrain_noisy.append(np.array(x_train_noisy)[random_indices].flatten())\n",
    "    X_pretrain_band.append(np.array(x_train_band)[random_indices])\n",
    "    X_pretrain_band_noisy.append(np.array(x_train_band_noisy)[random_indices])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69c5610-8dad-4d05-8bbb-fa34031d9c9c",
   "metadata": {},
   "source": [
    "# Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e2ac17-a4b5-4a6e-a6eb-d2e63438b0c8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-08T13:09:00.141311Z",
     "iopub.status.idle": "2024-07-08T13:09:00.141417Z",
     "shell.execute_reply": "2024-07-08T13:09:00.141359Z",
     "shell.execute_reply.started": "2024-07-08T13:09:00.141354Z"
    }
   },
   "outputs": [],
   "source": [
    "sampling_rate/np.min(np.hstack(filtered_peak_freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4957e6c-e0cc-4d90-a495-348a8bbab3cd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-08T13:09:00.141885Z",
     "iopub.status.idle": "2024-07-08T13:09:00.142002Z",
     "shell.execute_reply": "2024-07-08T13:09:00.141941Z",
     "shell.execute_reply.started": "2024-07-08T13:09:00.141936Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "#Pretraining\n",
    "from reservoir.reservoir import init_matrices\n",
    "from connexion_generation.hadsp import run_algorithm\n",
    "from scipy import sparse\n",
    "\n",
    "# Evaluating\n",
    "from performances.esn_model_evaluation import init_and_train_model_for_classification, predict_model_for_classification, compute_score\n",
    "from performances.esn_model_evaluation import init_and_train_model_for_prediction\n",
    "\n",
    "\n",
    "# score for prediction\n",
    "start_step = 30\n",
    "end_step = 500\n",
    "SLICE_RANGE = slice(start_step, end_step)\n",
    "RESERVOIR_SIZE = 500\n",
    "\n",
    "nb_jobs_per_trial = 12\n",
    "function_name = \"desp\" # \"desp\" ou \"hadsp\" or \"random\"\n",
    "data_type = \"normal\" # \"normal\" ou \"noisy\"\n",
    "variate_type = \"multi\" # \"multi\" ou \"uni\"\n",
    "if variate_type == \"uni\" and is_multivariate:\n",
    "    raise ValueError(f\"Invalid variable type: {variate_type}\")\n",
    "    \n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest values for the parameters you want to optimize\n",
    "    # COMMON\n",
    "    input_scaling = trial.suggest_float('input_scaling', 0.01, 0.2, step=0.005)\n",
    "    bias_scaling = trial.suggest_float('bias_scaling', 0, 0.2, step=0.005)\n",
    "    leaky_rate = trial.suggest_float('leaky_rate', 1, 1)\n",
    "    input_connectivity = trial.suggest_float('input_connectivity', 1, 1)\n",
    "    network_size = trial.suggest_int('network_size', RESERVOIR_SIZE, RESERVOIR_SIZE)\n",
    "    ridge = trial.suggest_int('ridge', -15, 1)\n",
    "    RIDGE_COEF = 10**ridge\n",
    "\n",
    "    min_window_size = sampling_rate/np.max(np.hstack(filtered_peak_freqs))\n",
    "    max_window_size = sampling_rate/np.min(np.hstack(filtered_peak_freqs))\n",
    "\n",
    "    # HADSP\n",
    "    if function_name == \"hadsp\":\n",
    "        target_rate = trial.suggest_float('target_rate', 0.5, 1, step=0.01)\n",
    "        rate_spread = trial.suggest_float('rate_spread', 0.01, 0.4, step=0.005)\n",
    "        method = trial.suggest_categorical(\"method\", [\"random\", \"pearson\"])\n",
    "    # DESP\n",
    "    elif function_name == \"desp\":\n",
    "        variance_target = trial.suggest_float('min_variance', 0.001, 0.02, step=0.001)\n",
    "        variance_spread = trial.suggest_float('variance_spread', 0.001, 0.05, step=0.002)\n",
    "        intrinsic_saturation = trial.suggest_float('intrinsic_saturation', 0.8, 0.98, step=0.02)\n",
    "        intrinsic_coef = trial.suggest_float('intrinsic_coef', 0.8, 0.98, step=0.02)\n",
    "        method = trial.suggest_categorical(\"method\", [\"pearson\"])\n",
    "    elif function_name == \"random\":\n",
    "        connectivity = trial.suggest_float('connectivity', 0, 1)\n",
    "        sr = trial.suggest_float('spectral_radius', 0.4, 1.6, step=0.01)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid function name: {function_name}\")\n",
    "\n",
    "    if function_name == \"hadsp\" or function_name == \"desp\":\n",
    "        connectivity = trial.suggest_float('connectivity', 0, 0)\n",
    "        weight_increment = trial.suggest_float('weight_increment', 0.001, 0.1, step=0.001)\n",
    "        max_partners = trial.suggest_int('max_partners', 10, 20)\n",
    "        use_full_instance = trial.suggest_categorical('use_full_instance', [True, False])\n",
    "        TIME_INCREMENT = trial.suggest_int('time_increment', int(min_window_size+1), 100) # int(min_window_size+1) or int(max_window_size)\n",
    "        max_increment_span = int(max_window_size) if int(max_window_size) - 100 < 0 else int(max_window_size) - 100\n",
    "        time_increment_span = trial.suggest_int('time_increment_span', 0, max_increment_span)\n",
    "        MAX_TIME_INCREMENT = TIME_INCREMENT + time_increment_span #int(max_window_size) or None or TIME_INCREMENT\n",
    "\n",
    "    # CROSS-VALIDATION METHODS\n",
    "    total_score = 0\n",
    "    for i in range(nb_splits):\n",
    "        if variate_type == \"multi\":\n",
    "            if is_instances_classification:\n",
    "                common_index = 1\n",
    "                common_size = X_train_band[i][0].shape[common_index]\n",
    "            else:\n",
    "                common_index = 1\n",
    "                common_size = X_train_band[i].shape[common_index]\n",
    "        else:\n",
    "            common_size = len(filtered_peak_freqs)\n",
    "            \n",
    "        # We want the size of the reservoir to be at least network_size\n",
    "        K = math.ceil(network_size / common_size)\n",
    "        n = common_size * K\n",
    "\n",
    "\n",
    "        pretrain_data = X_pretrain_band[i]\n",
    "        train_data = X_train_band[i]  # X_train_band_noisy_duplicated or X_train_band_duplicated\n",
    "        val_data = X_val_band_noisy[i] if data_type == \"noisy\" else X_val_band[i]\n",
    "\n",
    "        # UNSUPERVISED PRETRAINING \n",
    "        Win, W, bias = init_matrices(n, input_connectivity, connectivity,  K)\n",
    "        bias *= bias_scaling\n",
    "        Win *= input_scaling\n",
    "\n",
    "        if function_name == \"hadsp\":\n",
    "            W, _, _ = run_algorithm(W, Win, bias, leaky_rate, activation_function, pretrain_data, TIME_INCREMENT, weight_increment,\n",
    "                                 target_rate, rate_spread, function_name, is_instance=is_instances_classification, use_full_instance = use_full_instance, \n",
    "                                 max_increment=MAX_TIME_INCREMENT, max_partners=max_partners, method = method, n_jobs = nb_jobs_per_trial)\n",
    "        elif function_name == \"desp\":\n",
    "            W, _, _ = run_algorithm(W, Win, bias, leaky_rate, activation_function, pretrain_data, TIME_INCREMENT, weight_increment,\n",
    "                                    variance_target, variance_spread, function_name, is_instance=is_instances_classification, use_full_instance = use_full_instance, \n",
    "                                    max_increment=MAX_TIME_INCREMENT, max_partners=max_partners, method = method, \n",
    "                                    intrinsic_saturation=intrinsic_saturation, intrinsic_coef=intrinsic_coef, n_jobs = nb_jobs_per_trial)\n",
    "        elif function_name == \"random\":\n",
    "            eigen = sparse.linalg.eigs(W, k=1, which=\"LM\", maxiter=W.shape[0] * 20, tol=0.1, return_eigenvectors=False)\n",
    "            W *= sr / max(abs(eigen))\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid function: {function_name}\")\n",
    "        \n",
    "\n",
    "        # TRAINING and EVALUATION\n",
    "        if is_instances_classification:\n",
    "            reservoir, readout = init_and_train_model_for_classification(W, Win, bias, leaky_rate, activation_function, train_data, Y_train[i], n_jobs = nb_jobs_per_trial, ridge_coef=RIDGE_COEF, mode=\"sequence-to-vector\")\n",
    "            \n",
    "            Y_pred = predict_model_for_classification(reservoir, readout, val_data, n_jobs = nb_jobs_per_trial)\n",
    "            score = compute_score(Y_pred, Y_val[i], is_instances_classification)\n",
    "        else:\n",
    "            esn = init_and_train_model_for_prediction(W, Win, bias, leaky_rate, activation_function, train_data, Y_train[i], RIDGE_COEF)\n",
    "            \n",
    "            Y_pred =  esn.run(val_data, reset=False)\n",
    "            score = compute_score(Y_pred, Y_val[i], is_instances_classification)\n",
    "\n",
    "        total_score += score\n",
    "\n",
    "    average_score = total_score / nb_splits  # Average the score\n",
    "\n",
    "    return average_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a7cbad-31bd-49d2-a3c1-00d9ccb6aaab",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-08T13:09:00.142527Z",
     "iopub.status.idle": "2024-07-08T13:09:00.142628Z",
     "shell.execute_reply": "2024-07-08T13:09:00.142574Z",
     "shell.execute_reply.started": "2024-07-08T13:09:00.142569Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import re\n",
    "\n",
    "def camel_to_snake(name):\n",
    "    str1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', str1).lower()\n",
    "url= \"sqlite:///optuna_\" + camel_to_snake(dataset_name) + \"_db.sqlite3\"\n",
    "print(url)\n",
    "\n",
    "storage = optuna.storages.RDBStorage(\n",
    "    url=url,\n",
    "    engine_kwargs={\"pool_size\": 20, \"connect_args\": {\"timeout\": 10}},\n",
    ")\n",
    "study_name = function_name + \"_\" + dataset_name + \"_\" + data_type + \"_\" + variate_type\n",
    "print(study_name)\n",
    "\n",
    "direction = \"maximize\" if is_instances_classification else \"minimize\"\n",
    "sampler = TPESampler()\n",
    "\n",
    "def optimize_study(n_trials):\n",
    "    study = optuna.create_study(storage=storage, sampler=sampler, study_name=study_name, direction=direction, load_if_exists=True)\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "N_TRIALS = 400\n",
    "n_parallel_studies = 1\n",
    "trials_per_process = N_TRIALS // n_parallel_studies\n",
    "\n",
    "# Use joblib to parallelize the optimization\n",
    "Parallel(n_jobs=n_parallel_studies)(\n",
    "    delayed(optimize_study)(trials_per_process) for _ in range(n_parallel_studies)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afea5f7c-4fda-4977-b27a-be04731e9677",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee3d4e-e3c6-43fd-9ef8-cf41c858ebac",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3d64cab7d596f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hadsp_env",
   "language": "python",
   "name": "hadsp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
